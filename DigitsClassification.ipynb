{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_raw, y_train_raw), (x_test_raw, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Processing**  \n",
    "Looking at the data I found that x_train and y_train were np.ndarrays of length 60,000.  \n",
    "x_train's elements were also np.ndarrays of size 28 by 28 (i.e. each element of x_train represented a grayscale 28 by 28 pixel image of a written number).  \n",
    "y_train was one dimensional and contained labels for the images in x_train  \n",
    "\n",
    "Keras requires input data for images to be 4 dimensional so I reshape x_train and x_test such that each element is an ndarray of size 28 by 28 by 1 (i.e. each pixel value is an array of size 1 instead of a number)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tmp = x_train_raw.reshape(x_train_raw.shape[0], 28, 28, 1)\n",
    "x_test = x_test_raw.reshape(x_test_raw.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure I tuned hyperparameters without learning the test set, I split the training set into training and validation. I also split y_train accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 28, 28, 1)\n",
      "x_valid.shape = (10000, 28, 28, 1)\n",
      "x_test.shape = (10000, 28, 28, 1)\n",
      "y_train.shape = (50000,)\n",
      "y_valid.shape = (10000,)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train_tmp[:50000]\n",
    "x_valid = x_train_tmp[50000:]\n",
    "y_train = y_train_raw[:50000]\n",
    "y_valid = y_train_raw[50000:]\n",
    "\n",
    "print('x_train.shape = '+str(x_train.shape))\n",
    "print('x_valid.shape = '+str(x_valid.shape))\n",
    "print('x_test.shape = '+str(x_test.shape))\n",
    "\n",
    "print('y_train.shape = '+str(y_train.shape))\n",
    "print('y_valid.shape = '+str(y_valid.shape))\n",
    "print('y_test.shape = '+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I normalized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    return (arr-np.mean(arr))/np.std(arr)\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "x_valid = normalize(x_valid)\n",
    "x_test = normalize(x_test)\n",
    "\n",
    "# Another way of normalizing:\n",
    "#x_train = x_train / 255.0\n",
    "#x_valid = x_valid / 255.0\n",
    "#x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a CNN model**  \n",
    "I used a sequential model which can be built layer by layer (alternatively, Keras offers functional models which have more flexibility, e.g. any layer can be connected to any other layer, whether or not the layers are consecutive).\n",
    "\n",
    "The usual structure of CNNs is as follows:\n",
    "CONV --> POOL --> CONV --> ... --> FC (one or more) --> SOFTMAX\n",
    "I have used the same structure.\n",
    "\n",
    "Convolution layers \n",
    "* Each convolution layer should be followed by an activation layer (RELU) to add non-linearity to the network\n",
    "* As we increase depth, number of filters should increase\n",
    "* Filter size should be odd to allow for a central pixel\n",
    "* Padding should be used if border information of the image is important (in this case it was reasonable to expect digits to be close to the center the image so I did not use padding)\n",
    "\n",
    "Max pooling layers \n",
    "* Pooling is used to reduce size of representation, speed up computations, and make features more robust with respect to spatial location\n",
    "* Pool size should be low and should decrease over time to ensure dimensions are not decreased too rapidly (since I started with pool size of only 2 by 2, I did not need to decrease it)\n",
    "\n",
    "Dropout layers\n",
    "* Used to avoid overfitting\n",
    "* A dropout layer randomly sets a fraction of the inputs to 0 at each update during training\n",
    "\n",
    "Fully Connected layers\n",
    "* One or more fully connected layers are used to learn the classifier (once feature extraction has been completed by the convolution layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=28, kernel_size=(5,5),strides=(1,1), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=40, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten()) # flatten to get input for dense layer\n",
    "model.add(Dense(150, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10,activation=tf.nn.softmax)) # number of neurons must be same as number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 41s 822us/step - loss: 0.1806 - acc: 0.9415\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 40s 805us/step - loss: 0.0667 - acc: 0.9793\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 42s 839us/step - loss: 0.0513 - acc: 0.9836\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 41s 813us/step - loss: 0.0425 - acc: 0.9863\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 43s 853us/step - loss: 0.0376 - acc: 0.9879\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.0326 - acc: 0.99000s - loss: 0.0326 - acc\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 43s 859us/step - loss: 0.0298 - acc: 0.9900\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 43s 853us/step - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 41s 818us/step - loss: 0.0243 - acc: 0.9924\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 0.0237 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ce804afd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training accuracy was high at 99.8%  \n",
    "Validation accuracy was also high at 99.3% (and lower than training accuracy as expected)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 16s 317us/step\n",
      "[0.006352803620944469, 0.99792]\n",
      "10000/10000 [==============================] - 3s 311us/step\n",
      "[0.02890042385223642, 0.9927]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x_train, y_train))\n",
    "print(model.evaluate(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ascertain whether high training and validation accuracies were a result of overfitting or a good model, I finally ran the final model for the test data set.\n",
    "A high accuracy of 99.2% was achieved on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 311us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024913702316703347, 0.9924]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model to Disk**  \n",
    "Models can take a considerable time to train. \n",
    "While this is a significantly fast model to learn I saved this model for demonstration purposes.\n",
    "The structure of the model was saved in a .json file while the weights were saved in a .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "model_json = model.to_json()\n",
    "with open(\"model_backup.json\", \"w\") as f:\n",
    "    f.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(\"model_backup.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model from Disk**\n",
    "Uncomment and the following snippet to load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 326us/step\n",
      "[0.024913702316703347, 0.9924]\n"
     ]
    }
   ],
   "source": [
    "# load model structure\n",
    "with open('model_backup.json', 'r') as f:\n",
    "    model_json2 = f.read()\n",
    "model2 = model_from_json(model_json2)\n",
    "\n",
    "# load weights\n",
    "model2.load_weights(\"model_backup.h5\")\n",
    " \n",
    "# compile loaded model\n",
    "model2.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# evaluate on test data\n",
    "print (model2.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo**  \n",
    "The following function can be used to identify digits from the dataset using the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(i,from_test):\n",
    "    if from_test:\n",
    "        plt.imshow(x_test_raw[i], cmap='Greys')\n",
    "        print('True Label:',y_test[i])\n",
    "        pred = model.predict(x_test[i].reshape(1, 28, 28, 1))\n",
    "        print('Predicted Label:',np.argmax(pred))\n",
    "    else:\n",
    "        plt.imshow(x_train_raw[i], cmap='Greys')\n",
    "        print('True Label:',y_train[i])\n",
    "        pred = model.predict(x_train[i].reshape(1, 28, 28, 1))\n",
    "        print('Predicted Label:',np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Label:', 7)\n",
      "('Predicted Label:', 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=60\n",
    "classify(i,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***References:***\n",
    "* https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n",
    "* https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
